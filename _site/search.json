[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data analysis, science and other stuff ü§ì",
    "section": "",
    "text": "Hello, welcome to my blog.\nMy name is Juan Pablo, I have a PhD in Biotechnology from the Universidad Aut√≥noma Metropolitana, Mexico City.\nIn this blog I share posts with topics of my interest, such as data analysis with R code, science communication and other things that will take shape little by little.\nSome time ago I maintained a blog called ‚ÄúR in the Lab‚Äù focused exclusively on the analysis with R of data obtained in the laboratory of chemical and biological sciences, but after some stumbles I decided to start again with a blog where I could write about any topic.\nPreviously I was using the ‚Äúblogdown‚Äù package, but I must admit that things became a bit tedious, especially the maintenance and the inclusion of new posts. In the search for alternatives I found the fabulous post by Rebecca Barter - Thanks, Quarto, for saving my blog!, which gave me the idea for the design of my new blog.\nIf you have any questions about any of the posts please email me at jpch_26@outlook.com or jpch_biotech@outlook.com. In the About the author section you will find my social networks, you can also contact me there!\nThank you very much for visiting my blog, I hope you find it useful, see you next time! ü§ì\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nR Tutorial: Analysis of results of a nested experimental design\n\n\n\n\n\n\n\nR\n\n\ntutorial\n\n\nstatistical inference\n\n\nnested design\n\n\n\n\nA tutorial with R code for analyzing the results of nested designs\n\n\n\n\n\n\nOct 11, 2023\n\n\n\n\n\n\n  \n\n\n\n\nWhat is science? - The way we understand and model reality\n\n\n\n\n\n\n\nscience communication\n\n\nscientific method\n\n\nscientific thinking\n\n\n\n\nSome ideas about science\n\n\n\n\n\n\nSep 28, 2023\n\n\n\n\n\n\n  \n\n\n\n\nStatistical Inference with R\n\n\n\n\n\n\n\nR\n\n\nstatistical inference\n\n\nstatistics\n\n\npopulation\n\n\nsample\n\n\nparameters\n\n\nmean\n\n\nvariance\n\n\nstandard deviation\n\n\n\n\nSome statistical inference concepts and terms explained using R\n\n\n\n\n\n\nSep 27, 2023\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About the author",
    "section": "",
    "text": "Hello! Welcome to my personal blog.\nMy name is Juan Pablo. I have a PhD in Biotechnology from the Universidad Aut√≥noma Universidad Aut√≥noma Metropolitana.\nIn this blog I write about various topics of my interest such as data analysis and science in general. I hope you find it useful.\nYou can contact me through my email or my social networks:\njpch_26@outlook.com\njpch_biotech@outlook.com\nLinkedIn\nTwitter\nMy certifications:\nThe R Programming Environment\nIntroducci√≥n a Data Science: Programaci√≥n Estad√≠stica con R\nProgramming in R for Data Science\nExperimentation for Improvement\nProfessional Certificate: Data Analysis for Life Sciences\nI have also published some scientific articles, which can be consulted in my profile at Scholar Google.\nAll text, code and data in the tutorials are freely available under the Creative Commons Attribution 4.0 International License.\nThank you so much for visiting my blog! ü§ì"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn‚Äôt specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/statistical-inference/index.html",
    "href": "posts/statistical-inference/index.html",
    "title": "Statistical Inference with R",
    "section": "",
    "text": "Perfection is always impossible; always it‚Äôs an approximation"
  },
  {
    "objectID": "posts/statistical-inference/index.html#introduction",
    "href": "posts/statistical-inference/index.html#introduction",
    "title": "Statistical Inference with R",
    "section": "Introduction",
    "text": "Introduction\nFormally, statistical inference can be defined as the process through which inferences about a population are made based on certain statistics calculated from a sample of data drawn from that population.\nIf your job is related to any kind of science I‚Äôm positive you know that statistical inference plays an important role in your results validations. A single statement is often used as irrefutable evidence that you have succeeded in your research: ‚Äúthis results showed significant differences (P &lt; 0.05)‚Äù. But does anything showing significant differences really mean anything?\nI‚Äôm going to try to answer these and more questions with some help, of course, of R code."
  },
  {
    "objectID": "posts/statistical-inference/index.html#populations-samples-parameters-and-statistics",
    "href": "posts/statistical-inference/index.html#populations-samples-parameters-and-statistics",
    "title": "Statistical Inference with R",
    "section": "Populations, Samples, Parameters and statistics",
    "text": "Populations, Samples, Parameters and statistics\nFrom Cambridge Dictionary an inference is a guess that you make or an opinion that you form based on the information that you have. Statistically, the objective of an inference is to draw conclusions about population from a sample.\nBy population I mean the complete set of objects of your interest and can be the trees from a particular species or even the elements from a continuous process like chip cookies in a cookies factory (yeah, I like chip cookies). Most of the time, you don‚Äôt have access to the entire population simply because is too big and it would be impractical analyze each element or, as I said, the population can be considered like a continuous.\nThis is the place where the statistical inference can help. All that is needed is a sample of the population, which is called a sample. For this you must be sure that you sampling process ensures that each element in the population has the same chance to be selected. Once you have your sample you may be interested in some population property, so you proceed to measure this feature on each sample element. This property can be the height, some gene expression, the amount of sugar, the hardness, etc.\nFinally, you calculate a number that summarize the measured feature of your sample. These numbers are usually the mean, the variance, and the standard deviation, which as a whole are referred as statistics.\nWith some assumptions, from your statistics you can infer the population parameters. In other words, from your statistics you can estimate the mean, standard deviation and variance of the whole population.\nSee the next figure where I illustrate all process with cookies:"
  },
  {
    "objectID": "posts/statistical-inference/index.html#sample-mean",
    "href": "posts/statistical-inference/index.html#sample-mean",
    "title": "Statistical Inference with R",
    "section": "Sample Mean",
    "text": "Sample Mean\nYou can calculate the sample mean with the next equation:\n\n\n\n\n\nThe previous is the sum (summation) of all sample measurements divided by the sample size (n). i is the index of each element in your sample.\nWith R code in our previous sample:\n\nms_trees &lt;- sum(sample_trees) / length(sample_trees)\nms_trees\n\n[1] 15.552"
  },
  {
    "objectID": "posts/statistical-inference/index.html#sample-variance",
    "href": "posts/statistical-inference/index.html#sample-variance",
    "title": "Statistical Inference with R",
    "section": "Sample Variance",
    "text": "Sample Variance\nFor the sample variance you use the next equation:\n\n\n\n\n\nThis is the summation of the differences between each measurement in the sample and the sample mean. Each difference is squared, so negative and positive differences will not cancel each other. Then you divide the sum by the sample size minus one.\nWith R code:\n\nvs_trees &lt;- sum((sample_trees - ms_trees)^2) / (length(sample_trees) - 1)\nvs_trees\n\n[1] 10.32456\n\n\nIf you are wondering why we have divided by n - 1, I can briefly tell you that this way offers the best estimation of the population variance. You can also check out the next nice page: Why divide by N - 1 when calculating the variance of a sample?. To obtain the standard deviation you simply calculate the squared root of the variance, this way you have a dispersion sample measurement in the original measurement units.\n\nss_trees &lt;- sqrt(vs_trees)\nss_trees\n\n[1] 3.213186"
  },
  {
    "objectID": "posts/statistical-inference/index.html#population-mean",
    "href": "posts/statistical-inference/index.html#population-mean",
    "title": "Statistical Inference with R",
    "section": "Population mean",
    "text": "Population mean\nTo calculate population mean we use the next equation:\n\n\n\n\n\nYou can see that this equation is pretty the same as sample mean, but here N refers to the entire population size. Let‚Äôs calculate the mean in our previous data.\n\nmp_trees &lt;- sum(population_trees) / length(population_trees)\nmp_trees\n\n[1] 14.89803\n\n\nInstead of the previous operation you can use the mean() function with the same purpose:\n\nmean(population_trees)\n\n[1] 14.89803"
  },
  {
    "objectID": "posts/statistical-inference/index.html#population-variance",
    "href": "posts/statistical-inference/index.html#population-variance",
    "title": "Statistical Inference with R",
    "section": "Population variance",
    "text": "Population variance\nThe equation for population variance:\n\n\n\n\n\nNote that here we divide by the entire population size N, not by n-1 as in sample variance. Let‚Äôs calculate this parameter in our previous data:\n\nsum_square &lt;- sum((population_trees - mean(population_trees))^2)\npv_trees &lt;- sum_square / length(population_trees)\npv_trees\n\n[1] 15.39988\n\n\nYou can also calculate this parameter directly with variance() function:\n\nvar(population_trees)\n\n[1] 15.41016\n\n\nThere‚Äôs a sightly difference, but nothing to be worried about.\nCalculating standard deviation is also easy with sd() function:\n\nsd(population_trees)\n\n[1] 3.925577\n\n\nNote that population mean and standard deviation are close to those specified in the data simulation code rnorm(1500, mean = 15, sd = 4).\nIt is also important to mention that the mean(), var() and sd() functions can also be used on any sample data. You can try this as an exercise."
  },
  {
    "objectID": "posts/statistical-inference/index.html#mean-distribution",
    "href": "posts/statistical-inference/index.html#mean-distribution",
    "title": "Statistical Inference with R",
    "section": "Mean distribution",
    "text": "Mean distribution\nThe concept of distribution can also be applied to statistics like mean. From my cookie population let‚Äôs take repeatedly samples of size 5 and then make an histogram:\n\nset.seed(151) # For reproducibility\n\n# 1000 samples\nn_samples &lt;- 1000\n\n# Empty vector where all means will be stored \nmean_cookies &lt;- vector(\"numeric\", length = n_samples)\n\n# Take a random sample of size 5, calculate the mean and save it in previous vector\n# Repeat the process 1000 times\nfor (i in 1:n_samples) {\n  mean_cookies[i] &lt;- mean(sample(diameter$D, size = 5)) \n}\n\n# Make a data frame with all means from samples of size 5\nmean_cookies &lt;- tibble(mean_n5 = mean_cookies)\n\n# Histogram\nfreq_hist_mean &lt;- mean_cookies %&gt;% \n  ggplot(aes(x = mean_n5)) +\n  geom_histogram(color = \"black\", fill = \"white\", binwidth = 0.1) +\n  xlab(\"Diameter (cm)\") +\n  ylab(\"Count\") +\n  theme_classic() \nfreq_hist_mean\n\n\n\n\n\n\n\n\nThe previous code can be repeated with other sample sizes. This will be important in a later section (Central Limit Theorem)."
  },
  {
    "objectID": "posts/statistical-inference/index.html#the-normal-distribution",
    "href": "posts/statistical-inference/index.html#the-normal-distribution",
    "title": "Statistical Inference with R",
    "section": "The normal distribution",
    "text": "The normal distribution\nSince it is rare to know the actual distribution of data, we have to resort to theoretical distributions. There are a lot of such distributions and undoubtedly the normal distribution is the most important in statistical inference. This distribution applies to continuous data (length, weight, temperature, etc.) and is defined by the following equation:\n\n\n\n\n\nA graph of the above equation looks like this (with mean equal to zero and standard deviation equal to one):"
  },
  {
    "objectID": "posts/statistical-inference/index.html#the-students-t-distribution",
    "href": "posts/statistical-inference/index.html#the-students-t-distribution",
    "title": "Statistical Inference with R",
    "section": "The Student‚Äôs t Distribution",
    "text": "The Student‚Äôs t Distribution\nWhen you have small sample sizes and you don‚Äôt know the real deviation standard of the population, you can use the t distribution to made a good supposition of the real distribution. The shape of this distribution depends on the sample size, and for big sample sizes the t distribution tends to be normal:\n\n\n\n\n\n\n\n\n\nThe black line corresponds to a sample size of 2, the red line to a sample size of 4, the blue one to a size of 10, and the green one to a size of 50."
  },
  {
    "objectID": "posts/statistical-inference/index.html#sample-mean-or-sample-average",
    "href": "posts/statistical-inference/index.html#sample-mean-or-sample-average",
    "title": "Statistical Inference with R",
    "section": "Sample Mean or Sample Average",
    "text": "Sample Mean or Sample Average\nWe can calculate the sample mean with the following equation:\n\n\n\n\n\nThe above is the sum (summation) of all the measurements in the sample divided by the sample size (n). i is the index of each item or measurement.\nWith R code in our previous sample:\n\nms_trees &lt;- sum(sample_trees) / length(sample_trees)\nms_trees\n\n[1] 15.552\n\n\nWe can directly use the mean() function with our data to calculate the mean:\n\nmean(sample_trees)\n\n[1] 15.552"
  },
  {
    "objectID": "posts/statistical-inference/index.html#sample-variance-and-dtandard-deviation",
    "href": "posts/statistical-inference/index.html#sample-variance-and-dtandard-deviation",
    "title": "Statistical Inference with R",
    "section": "Sample Variance and Dtandard Deviation",
    "text": "Sample Variance and Dtandard Deviation\nFor the sample variance you use the next equation:\n\n\n\n\n\nThis is described as the sum of the differences between each sample measurement and the sample mean. Each difference is squared, so negative and positive differences do not cancel each other out. The sum is then divided by the sample size minus one.\nWith R code:\n\nvs_trees &lt;- sum((sample_trees - ms_trees)^2) / (length(sample_trees) - 1)\nvs_trees\n\n[1] 10.32456\n\n\nIf you are wondering why we have divided by n - 1, I can briefly tell you that this way offers the best estimation of the population variance. You can also check out the next page: Why divide by N - 1 when calculating the variance of a sample?.\nTo obtain the standard deviation, it is sufficient to calculate the square root of the variance, thus providing a measure of the dispersion of the sample in the original units of measurement:\n\nss_trees &lt;- sqrt(vs_trees)\nss_trees\n\n[1] 3.213186\n\n\nAs in the case of the mean, with R code we can obtain the variance and standard deviation directly with the var() and sd() functions, respectively:\n\n#Sample varianza\nvar(sample_trees)\n\n[1] 10.32456\n\n# Standard deviation \nsd(sample_trees)\n\n[1] 3.213186"
  },
  {
    "objectID": "posts/statistical-inference/index.html#mean-or-average-of-the-population",
    "href": "posts/statistical-inference/index.html#mean-or-average-of-the-population",
    "title": "Statistical Inference with R",
    "section": "Mean or average of the population",
    "text": "Mean or average of the population\nTo calculate population mean we use the next equation:\n\n\n\n\n\nYou can see that this equation is quite similar to the sample mean, but here N refers to all elements of the population. Let‚Äôs calculate the mean in our simulated data:\n\nmp_trees &lt;- sum(population_trees) / length(population_trees)\nmp_trees\n\n[1] 14.89803\n\n\nInstead of the previous operation you can use the mean() function with the same purpose:\n\nmean(population_trees)\n\n[1] 14.89803"
  },
  {
    "objectID": "posts/statistical-inference/index.html#variance-and-standard-deviation-of-the-population",
    "href": "posts/statistical-inference/index.html#variance-and-standard-deviation-of-the-population",
    "title": "Statistical Inference with R",
    "section": "Variance and Standard Deviation of the Population",
    "text": "Variance and Standard Deviation of the Population\nThe equation for population variance:\n\n\n\n\n\nNote that here we divide by the total population size N, not by n-1 as in the sampling variance. Let us calculate this parameter in our previous data:\n\nsum_square &lt;- sum((population_trees - mean(population_trees))^2)\npv_trees &lt;- sum_square / length(population_trees)\npv_trees\n\n[1] 15.39988\n\n\nThe base functions of R do not have one that calculates the population variance, but this can be solved by multiplying the value obtained with var()by (n-1)/n:\n\nvarp_trees &lt;- var(population_trees)\nvarp_trees &lt;- varp_trees * (length(population_trees) - 1) / length(population_trees)\nvarp_trees\n\n[1] 15.39988\n\n\nTo calculate the standard deviation it would be sufficient to obtain the square root of the previous value:\n\nsqrt(varp_trees)\n\n[1] 3.924268\n\n\nNote that the population mean and standard deviation are close to those specified in the code we used to simulate the data rnorm(1500, mean = 15, sd = 4)."
  },
  {
    "objectID": "posts/statistical-inference/index.html#sampling-mean-distribution",
    "href": "posts/statistical-inference/index.html#sampling-mean-distribution",
    "title": "Statistical Inference with R",
    "section": "Sampling Mean Distribution",
    "text": "Sampling Mean Distribution\nThe concept of distribution can also be applied to statistics such as the mean. To illustrate the above for our population of cookies let‚Äôs repeatedly take samples of size 5 and make a histogram with the averages of these samples:\n\nset.seed(151) # For reproducibility\n\n# 1000 samples\nn_samples &lt;- 1000\n\n# Empty vector where all means will be stored \nmean_cookies &lt;- vector(\"numeric\", length = n_samples)\n\n# Take a random sample of size 5, calculate the mean and save it in previous vector\n# Repeat the process 1000 times\nfor (i in 1:n_samples) {\n  mean_cookies[i] &lt;- mean(sample(diameter$D, size = 5)) \n}\n\n# Make a data frame with all means from samples of size 5\nmean_cookies &lt;- data.frame(mean_n5 = mean_cookies)\n\n# Histogram\nfreq_hist_mean &lt;- mean_cookies %&gt;% \n  ggplot(aes(x = mean_n5)) +\n  geom_histogram(color = \"black\", fill = \"white\", binwidth = 0.1) +\n  xlab(\"Diameter (cm)\") +\n  ylab(\"Count\") +\n  theme_classic() \nfreq_hist_mean\n\n\n\n\n\n\n\n\nThe previous code can be repeated with other sample sizes and this will be important in a later section (Central Limit Theorem)."
  },
  {
    "objectID": "posts/statistical-inference/index.html#students-t-distribution",
    "href": "posts/statistical-inference/index.html#students-t-distribution",
    "title": "Statistical Inference with R",
    "section": "Student‚Äôs t distribution",
    "text": "Student‚Äôs t distribution\nWhen sample sizes are small and the true standard deviation of the population is not known, Student‚Äôs t-distribution can be used to make a good guess of the distribution of the data. The shape of this distribution depends on the sample size and for large sample sizes the t-distribution tends to be normal:\n\n\n\n\n\n\n\n\n\nThe black line corresponds to a sample size of 2, the red line to a sample size of 4, the blue one to a size of 10, and the green one to a size of 50."
  },
  {
    "objectID": "posts/what-is-science/index.html",
    "href": "posts/what-is-science/index.html",
    "title": "What is science? - The way we understand and model reality",
    "section": "",
    "text": "When you want to awaken people‚Äôs interest in science, it is important to explain in a general way what it consists of. I do not think I have enough experience to give a detailed explanation of what science is, so I will limit myself to describing what it represents for me and some related concepts.\n\nWhat is science?\nScience can be defined as a human activity in charge of gathering knowledge and describing the different phenomena that make up reality in all its extension and complexity.\nKnowing and describing different natural phenomena, including social phenomena, gives us the possibility to develop and improve solutions that satisfy diverse human needs. In this way we can use scientific knowledge to influence reality itself: we cure diseases, improve processes that did not work well before, send satellites to outer space and many other things. At the beginning, when scientific knowledge is produced, it may not have any use, but over time some use may be found, which may depend on advances in other areas of science. Also, of course, all of the above also depends on the branch of science to which we are referring.\nScience, above all, is a social activity and, like all human beings, people who do science can and are susceptible to making mistakes. It is worth noting that unlike other human activities, such as religion or politics, science has the necessary mechanisms to detect and correct errors, biases, omissions and other mistakes. Science is undoubtedly an activity that requires the people involved to be self-critical and always willing to improve based on their mistakes.\nAlthough science is not a panacea, a cure for all the ills and problems that afflict humanity, it offers us an objective way to bring prosperity to every human being.\n\n\nThe scientific method\nHow is science done? Each branch of science has its own methods for generating knowledge. To do science we can follow some general guidelines, but not recipes that must be followed point by point. Below I list several steps that we can follow to generate scientific knowledge, but, in line with what I have just mentioned, we must bear in mind that there may be intermediate steps or even some points can be eliminated or modified depending on the area of knowledge we want to address.\n\nRecognize a question. This may be related to some unexplained phenomenon or a problem to which we wish to provide a solution.\nMake an adequate conjecture, a hypothesis, of the possible answers to our question. This is usually done through literature research or with the help of other means.\nPredict the consequences of the hypothesis. Once we have researched the possible answers, we make a prediction of what they would imply if they were actually true.\nWe conduct several experiments to test our predictions. From these experiments we obtain data or records. This step is important because it helps us test the hypothersis against the reality.\nIf our data or records do not agree with our previous predictions, we go back on the fly and look for or generate another hypothesis that might provide the answer to our question.\n\n\n\n\nFlow chart of the scientific method\n\n\nAnd what conditions must be met for something to be considered science? There are two key aspects:\n\nThe observations and/or experiments produced when investigating a particular phenomenon must be reproducible. That is, each time we repeat the experiment and our measurements (or records) under the same conditions, the results should be very similar to each other, even if the research is attempted to be reproduced in different places or countries.\nEvery scientific proposition must be falsifiable, which means that we must be able to formulate experiments whose results would deny the explanations given by such propositions. If it is not possible to formulate, at least with imagination, experiments aimed at demonstrating that what is said by a science is false, then it is quite possible that we are talking not of a science, but of a pseudoscience.\n\n\n\nScientific measurements\nMeasurement plays a central role in science. A measurement, in very general terms, is the assignment of a number to a certain phenomenon in nature. Measurements must be objective and do not depend on the judgment of the person making them. For the mass of an object, for example, we can use a balance, which will show us a number with some associated unit (grams, kilograms, etc.). Undoubtedly, an important part of the development of science is to find good and rigorous ways of making measurements.\n\n\n\nSome basic measuring instruments\n\n\nIt is important to mention that, depending on the phenomenon, there may not be rigorous ways to measure it. How do we measure some of the phenomena described by the social sciences?\n\n\nHypothesis, law and theory\nAs we saw earlier, a hypothesis is an assumption that can be substantiated in research through various means. When a hypothesis is sufficiently tested and no contradiction is found, it is considered a law or principle. A set of concepts, abstractions and laws related to a natural phenomenon becomes a theory. Theories can be considered as the highest level of scientific knowledge, since from these theories research problems can be posed and thus generate more knowledge.\nIt should be noted that there is no hierarchical relationship between law and theory. A theory is not below a law, nor vice versa. In the case of laws, they usually establish the relationship between different concepts and are simpler than theories. Also, depending on the branch of science, laws may not be as rigorous; a law is not the same in biology as in physics, for example. As for theories, they explain a set of phenomena (they are broader than laws) and are susceptible to change and improve over time based on the evidence that is generated from them or with the help of other branches of science.\n\n\nMyths about scientific research\nThere are some beliefs that somehow contribute to people‚Äôs lack of interest in science, mainly two:\n\nScientific research is very complicated and difficult. False, any human being can do research if they follow the right process for the problem they want to address. If we think about it carefully we are always doing research in our daily life.\nResearch is not linked to the everyday world. Also false, many of the conveniences and services we enjoy today have been derived from scientific research: smartphones, internal combustion engines, medicines, nylon, among many other products.\n\nPersonally, I believe that these misconceptions are due to the inability of research centers, universities and governments to communicate science to as many people as possible. Added to this is the superfluous treatment that the sensationalist media give to science and its findings.\n\n\nDeduction and induction\nDeduction and induction play a fundamental role in scientific work.\n\nDeduction. Reaching a particular conclusion from general premises. This is what we do when we formulate hypotheses from existing knowledge or when we make predictions based on established theories and laws.\nInduction. Reaching a general conclusion from observation of particular cases. The conclusion is considered probable, but not necessarily certain since there is always the possibility that new observations or evidence will disprove the conclusion. This is what we do when we perform experimentation to test our hypotheses.\n\nFrom both definitions we can infer that deduction and induction are processes that feed back on each other: we derive hypotheses from existing knowledge (deduction), we test these hypotheses again and again, improving at each step the initial hypothesis (induction). When sufficiently tested, the hypothesis becomes part of the theory that will allow us to generate new hypotheses, thus repeating the process of deduction and induction.\n\n\nFinal reflection\nThe development of science depends and has depended on the contribution of many people throughout history. It is a constantly changing human activity where its different branches feed back to improve our understanding of the world and the universe of which we are a part.\nScientific thinking is within everyone‚Äôs reach, it is not exclusive to universities or special beings. To a greater or lesser extent we can all put into practice the scientific method to ask and solve questions about what surrounds us.\n\n\nTo learn more about this topic\nBelow is a list with a couple of references and web pages that may be of help if you wish to delve a little deeper into the subject of this publication.\nDahlstrom, M.F. (2014) ‚ÄòUsing narratives and storytelling to communicate science with nonexpert audiences‚Äô, Proceedings of the National Academy of Sciences, 111(supplement_4), pp.¬†13614‚Äì13620. Available at: https://doi.org/10.1073/pnas.1320645111.\nRose, S.P.R. (2003) ‚ÄòHow to (or not to) communicate science‚Äô, Biochemical Society Transactions, 31(2), pp.¬†307‚Äì312. Available at: https://doi.org/10.1042/bst0310307.\nscientific method (2023) Encyclop√¶dia Britannica. Available at: https://www.britannica.com/science/scientific-method (Accessed: 27 September 2023).\nWhat Is Science? (2021) NASA Science. Space Place. Explore Earth and Space! Available at: https://spaceplace.nasa.gov/science/en/ (Accessed: 27 September 2023).\nThe text in this publication is free to use under license Creative Commons Attribution 4.0 International License."
  },
  {
    "objectID": "posts/nested-designs/index.html",
    "href": "posts/nested-designs/index.html",
    "title": "R Tutorial: Analysis of results of a nested experimental design",
    "section": "",
    "text": "A nested design is a type of experimental design in which the levels of one factor are hierarchically nested within the levels of another factor. For example, let‚Äôs imagine that we are interested in the effect of a type of drug on the expression of a specific gene. For this we design a nested experiment with mice as experimental units (in the figure two mice per treatment), where we include a control. From each mouse we took three cells and in each one we evaluated the expression of the gene twice (technical repetitions).\n\n\n\n\n\nAs shown in the figure, our design has a hierarchical appearance.\nIn this type of design we distinguish between two types of factors: fixed and random. A fixed factor is one that has discrete or finite values, while a random factor can take many values. In our example the drug factor would be considered a fixed factor and the mouse, cell and repeated measurements factors would be considered random factors. Note how the random factors are similar, such as mouse and cell, but not identical to each other and these are successively nested until the fixed factor drug.\nNow let‚Äôs see how we can analyze the results of this type of experimental design with the help of R code. It is important to mention that I took as a basis the publication in nature methods: Nested designs and replicated the example shown using, of course, R code. In addition, I added an extra drug and performed a multiple comparisons test to establish significant differences between the means of each treatment.\nIf you are interested about how I simulated the data, please take a look at the code in the data_simulation script found in the repository of this tutorial: (link)."
  },
  {
    "objectID": "posts/nested-designs/index.html#anova-table",
    "href": "posts/nested-designs/index.html#anova-table",
    "title": "R Tutorial: Analysis of results of a nested experimental design",
    "section": "ANOVA Table",
    "text": "ANOVA Table\nAs can be seen in our graph, there seems to be a difference between the effect of drug 2 with the other two levels of this factor (drug 1 and control). We can define if there are significant differences by means of an ANOVA table and subsequently a multiple comparisons test.\nLet‚Äôs obtain the ANOVA table with the GAD package, first we have to specify the fixed and random factors:\n\ndrug &lt;- as.fixed(mice_data$A)\nmice &lt;- as.random(mice_data$B)\ncell &lt;- as.random(mice_data$C)\n\nTo fit the linear model we must take into account the relationship between our response and the previously specified factors:\n\ndata_aov &lt;- aov(\n  expr ~ drug + mice:drug + cell:mice:drug,\n  data = mice_data\n  )\n\nThe term mice:drug denotes the variability of mice within each treatment, and the term cell:mice:drug denotes the variability of cells within each mouse and in turn within each treatment.\nTo display the ANOVA table we use the gad() function:\n\ngad(data_aov)\n\nAnalysis of Variance Table\n\nResponse: expr\n                Df Sum Sq Mean Sq F value    Pr(&gt;F)    \ndrug             2 743.44  371.72  12.796  0.001058 ** \ndrug:mice       12 348.59   29.05   5.163 7.413e-06 ***\ndrug:mice:cell  60 337.59    5.63  11.153 &lt; 2.2e-16 ***\nResidual       150  75.67    0.50                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe gad() function distinguishes between fixed and random effects, as well as the nested structure between these factors, so it makes corrections to calculate the F-ratios. The reason for this is that, depending on whether we are considering fixed or random effects, the expected values for the error mean squares (EM) change as follows:\n\n\n\n\n\nIn the above equations it is possible to observe the nested structure in the mean squares. Also note how for the case of treatments (\\(MS_A\\)) the expected values add up to the contribution to the variation of mice and cells. Therefore, it is necessary to divide \\(MS_A\\) by \\(MS_B\\) to obtain the F-ratio and infer differences between treatments.\nImportantly, in the case of technical replicates the variability of this random factor is properly estimated by the mean square of the Residual term in our ANOVA table."
  },
  {
    "objectID": "posts/nested-designs/index.html#estimation-of-the-variability-of-each-factor",
    "href": "posts/nested-designs/index.html#estimation-of-the-variability-of-each-factor",
    "title": "R Tutorial: Analysis of results of a nested experimental design",
    "section": "Estimation of the variability of each factor",
    "text": "Estimation of the variability of each factor\nWhen dealing with random factors, we are mainly interested in estimating their contribution to the variability of the response, as opposed to fixed factors where we are interested in estimating their effect on the population mean.\nWith the lme4 package we can estimate the contribution to variability of mice, cells and properly the error term (technical replicates). First we need to convert the data type in columns A, B and C into factors and then use the lmer() function as follows:\n\nmice_data3 &lt;- mice_data %&gt;% \n  mutate(A = as.factor(A), B = as.factor(B), C = as.factor(C))\n\ndata_lme &lt;- lmer(expr ~ 1 + A + (1|B:A) + (1|C:B:A), data = mice_data3)\n\nNote that fitting the linear model with the lmer() function requires a somewhat different syntax than that used with aov() and gad(). To show the contribution to variability of each factor we use the summary() function with the data_lme object as argument:\n\nsummary(data_lme)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: expr ~ 1 + A + (1 | B:A) + (1 | C:B:A)\n   Data: mice_data3\n\nREML criterion at convergence: 684.4\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.76545 -0.53144 -0.02996  0.59495  2.20017 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n C:B:A    (Intercept) 1.7073   1.3066  \n B:A      (Intercept) 1.5615   1.2496  \n Residual             0.5045   0.7103  \nNumber of obs: 225, groups:  C:B:A, 75; B:A, 15\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  10.0519     0.6224  16.151\nA2            1.4654     0.8801   1.665\nA3           -2.9085     0.8801  -3.305\n\nCorrelation of Fixed Effects:\n   (Intr) A2    \nA2 -0.707       \nA3 -0.707  0.500\n\n\nUnder Random effects the term Residual refers to technical replicates, the term B:A to mice and the term C:B:A to cells."
  },
  {
    "objectID": "posts/nested-designs/index.html#multiple-comparisons",
    "href": "posts/nested-designs/index.html#multiple-comparisons",
    "title": "R Tutorial: Analysis of results of a nested experimental design",
    "section": "Multiple comparisons",
    "text": "Multiple comparisons\nThe glth() function of the multcomp package can be used to perform the multiple comparison test:\n\nmult_drug &lt;- glht(data_lme, linfct = mcp(A = \"Tukey\"))\nsummary(mult_drug)\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lmer(formula = expr ~ 1 + A + (1 | B:A) + (1 | C:B:A), data = mice_data3)\n\nLinear Hypotheses:\n           Estimate Std. Error z value Pr(&gt;|z|)    \n2 - 1 == 0   1.4654     0.8801   1.665   0.2188    \n3 - 1 == 0  -2.9085     0.8801  -3.305   0.0027 ** \n3 - 2 == 0  -4.3739     0.8801  -4.970   &lt;1e-04 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\nAlternatively or additionally it is also possible to use the HSD.test() function of the agricolae package. For this I specified the mean squared error for mice (29.05) as well as the degrees of freedom for this factor (12):\n\ntukey_hsd &lt;- with(mice_data, HSD.test(expr, A, DFerror = 12, MSerror = 29.05))\ntukey_hsd$groups\n\n       expr groups\n2 11.517297      a\n1 10.051919      a\n3  7.143408      b\n\n\nAccording to the results of the above analyses, we can conclude that drug 2 significantly reduced the gene expression levels compared to drug 1 and the control."
  }
]